!=	1
"word	1
(IntWritable	1
(itr.hasMoreTokens())	1
(otherArgs.length	1
)	2
+=	1
0	1
0;	1
1);	1
2)	1
:	2
<in>	1
<out>");	1
=	8
?	1
Configuration	1
Configuration();	1
Context	2
Exception	1
FileInputFormat.addInputPath(job,	1
FileOutputFormat.setOutputPath(job,	1
GenericOptionsParser(conf,	1
IOException,	2
IntSumReducer	1
IntWritable	2
IntWritable();	1
IntWritable(1);	1
IntWritable>{	1
InterruptedException	2
Iterable<IntWritable>	1
Job	1
Job(conf,	1
Mapper<Object,	1
Path(otherArgs[0]));	1
Path(otherArgs[1]));	1
Reducer<Text,IntWritable,Text,IntWritable>	1
StringTokenizer	1
StringTokenizer(value.toString());	1
String[]	1
System.err.println("Usage:	1
System.exit(2);	1
System.exit(job.waitForCompletion(true)	1
Text	2
Text();	1
Text,	2
TokenizerMapper	1
WordCount	1
args)	1
args).getRemainingArgs();	1
class	3
conf	1
context	2
context.write(key,	1
context.write(word,	1
count");	1
extends	2
final	1
for	1
if	1
import	12
int	1
itr	1
java.io.IOException;	1
java.util.StringTokenizer;	1
job	1
job.setCombinerClass(IntSumReducer.class);	1
job.setJarByClass(WordCount.class);	1
job.setMapperClass(TokenizerMapper.class);	1
job.setOutputKeyClass(Text.class);	1
job.setOutputValueClass(IntWritable.class);	1
job.setReducerClass(IntSumReducer.class);	1
key,	2
main(String[]	1
map(Object	1
new	9
one	1
one);	1
org.apache.hadoop.conf.Configuration;	1
org.apache.hadoop.examples;	1
org.apache.hadoop.fs.Path;	1
org.apache.hadoop.io.IntWritable;	1
org.apache.hadoop.io.Text;	1
org.apache.hadoop.mapreduce.Job;	1
org.apache.hadoop.mapreduce.Mapper;	1
org.apache.hadoop.mapreduce.Reducer;	1
org.apache.hadoop.mapreduce.lib.input.FileInputFormat;	1
org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;	1
org.apache.hadoop.util.GenericOptionsParser;	1
otherArgs	1
package	1
private	3
public	6
reduce(Text	1
result	1
result);	1
result.set(sum);	1
static	4
sum	2
throws	3
val	1
val.get();	1
value,	1
values)	1
values,	1
void	3
while	1
word	1
word.set(itr.nextToken());	1
wordcount	1
{	8
}	9
